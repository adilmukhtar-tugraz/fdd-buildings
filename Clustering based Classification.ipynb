{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4472fe-689e-467c-bd23-81e8aa24758b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, PowerTransformer\n",
    "import json \n",
    "base_dir = 'results/'\n",
    "import pickle\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import json\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3157ef60-3343-4985-bcb3-3c5ff2fc491b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_name):\n",
    "    df = pd.read_csv(base_dir+file_name, index_col='Datetime')\n",
    "    df.index = pd.to_datetime(df.index, format='%Y-%m-%d %H:%M:%S')\n",
    "    return df\n",
    "\n",
    "def train_binary_classifier_for_clusters(cluster_labels, data, model_name='logistic_regression', test_size=0.2, random_state=42, cv=True):\n",
    "    \"\"\"\n",
    "    Trains a binary classifier for each cluster.\n",
    "\n",
    "    Parameters:\n",
    "    - cluster_labels: Cluster labels assigned by KMeans or any clustering algorithm\n",
    "    - data: Input data (numpy array or pandas DataFrame)\n",
    "    - model_name: Name of the binary classifier ('logistic_regression', 'random_forest', 'svm')\n",
    "    - test_size: Proportion of the dataset to include in the test split (default is 0.2)\n",
    "    - random_state: Seed for random number generation (default is 42)\n",
    "\n",
    "    Returns:\n",
    "    - classifiers: Dictionary containing trained classifiers for each cluster\n",
    "    - results: Dictionary containing evaluation scores for each cluster\n",
    "    \"\"\"\n",
    "    \n",
    "    classifiers = {}\n",
    "    accuracy_scores = {}\n",
    "    # Initialize dictionary to store results\n",
    "    \n",
    "    # Identify unique clusters\n",
    "    unique_clusters = set(cluster_labels)\n",
    "    results = {}\n",
    "    \n",
    "    for cluster in unique_clusters:\n",
    "        if cluster == -1:\n",
    "            continue\n",
    "        print(f\"Cluster Number: {cluster}\")\n",
    "        results[str(cluster)] = {}\n",
    "        \n",
    "        #print(cluster)\n",
    "        # Select data points for the current cluster\n",
    "        cluster_indices = (cluster_labels == cluster)\n",
    "        X_cluster, y_cluster = data[cluster_indices], np.zeros(sum(cluster_indices))  # Target label for the cluster is 0\n",
    "\n",
    "        # Select an equal number of data points from other clusters\n",
    "        other_clusters = list(set(unique_clusters) - {cluster})\n",
    "        other_indices = []\n",
    "        df_other_clusters = pd.DataFrame()\n",
    "        \n",
    "        for other_cluster in other_clusters:\n",
    "            other_cluster_indices = np.where(cluster_labels == other_cluster)[0]\n",
    "            df_other = data.iloc[other_cluster_indices]\n",
    "            df_other_clusters = pd.concat([df_other_clusters, df_other])\n",
    "            \n",
    "        df_other_random = df_other_clusters.sample(n=X_cluster.shape[0], random_state=42)\n",
    "        X_other, y_other = df_other_random.values, np.ones(df_other_random.shape[0])\n",
    "        # Combine data for the current cluster and other clusters\n",
    "        X_combined = np.vstack([X_cluster, X_other])\n",
    "        y_combined = np.hstack([y_cluster, y_other])\n",
    "\n",
    "        # Train the specified binary classifier\n",
    "        if model_name == 'logistic_regression':\n",
    "            classifier = LogisticRegression(random_state=random_state)\n",
    "        elif model_name == 'random_forest':\n",
    "            classifier = RandomForestClassifier(random_state=random_state)\n",
    "        elif model_name == 'svm':\n",
    "            classifier = SVC(random_state=random_state)\n",
    "        elif model_name == 'naive_bayes':\n",
    "            classifier = GaussianNB()\n",
    "        else:\n",
    "            raise ValueError(\"Invalid model_name. Choose from 'logistic_regression', 'random_forest', or 'svm'.\")\n",
    "\n",
    "        if cv == True:\n",
    "            mean_accuracy, std_accuracy, mean_f1, std_f1, mean_precision, std_precision, mean_recall, std_recall = perform_cv_binary_classifier(X_combined, y_combined, classifier)\n",
    "            print(f'Mean Accuracy: {mean_accuracy:.4f} Std: {std_accuracy}')\n",
    "            print(f'Mean Precision: {mean_precision:.4f} Std: {std_precision}')\n",
    "            print(f'Mean Recall: {mean_recall:.4f} Std: {std_recall}')\n",
    "            print(f'Mean F1 Score: {mean_f1:.4f} Std: {std_f1}')\n",
    "            \n",
    "            results[str(cluster)]['Accuracy'] = [mean_accuracy, std_accuracy]\n",
    "            results[str(cluster)]['F1'] = [mean_f1, std_f1]\n",
    "            results[str(cluster)]['Precision'] = [mean_precision, std_precision]\n",
    "            results[str(cluster)]['Recall'] = [mean_recall, std_recall]\n",
    "\n",
    "        else:\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X_combined, y_combined, test_size=0.2, random_state=42)\n",
    "            classifier.fit(X_train, y_train)\n",
    "            \n",
    "            # Make predictions on the test data\n",
    "            y_pred = classifier.predict(X_test)\n",
    "\n",
    "            # Evaluate performance\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            precision = precision_score(y_test, y_pred)\n",
    "            recall = recall_score(y_test, y_pred)\n",
    "            f1 = f1_score(y_test, y_pred)\n",
    "            \n",
    "            print(f'Mean Accuracy: {accuracy:.4f}')\n",
    "            print(f'Mean Precision: {precision:.4f}')\n",
    "            print(f'Mean Recall: {recall:.4f}')\n",
    "            print(f'Mean F1 Score: {f1:.4f}')\n",
    "            classifiers[str(cluster)] = classifier\n",
    "            \n",
    "    return results, classifiers\n",
    "\n",
    "def perform_cv_binary_classifier(X, y, classifier):\n",
    "    num_folds = 10\n",
    "\n",
    "    # Create a StratifiedKFold object\n",
    "    stratified_kfold = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Lists to store evaluation results for each fold\n",
    "    accuracy_scores = []\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "    f1_scores = []\n",
    "    \n",
    "    # Perform cross-validation\n",
    "    for train_index, test_index in stratified_kfold.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "        # Fit the model on the training data\n",
    "        classifier.fit(X_train, y_train)\n",
    "    \n",
    "        # Make predictions on the test data\n",
    "        y_pred = classifier.predict(X_test)\n",
    "    \n",
    "        # Evaluate performance\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "        # Append scores to the lists\n",
    "        accuracy_scores.append(accuracy)\n",
    "        precision_scores.append(precision)\n",
    "        recall_scores.append(recall)\n",
    "        f1_scores.append(f1)\n",
    "\n",
    "    \n",
    "    # Calculate and print mean scores across all folds\n",
    "    mean_accuracy, std_accuracy = np.mean(accuracy_scores), np.std(accuracy_scores)\n",
    "    mean_precision, std_precision = np.mean(precision_scores), np.std(precision_scores)\n",
    "    mean_recall, std_recall = np.mean(recall_scores), np.std(recall_scores)\n",
    "    mean_f1, std_f1 = np.mean(f1_scores), np.std(f1_scores)\n",
    "    \n",
    "    \n",
    "    return mean_accuracy, std_accuracy, mean_f1, std_f1, mean_precision, std_precision, mean_recall, std_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75015007-6d81-45ef-9f4f-e99ef4c7b6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'faulty_data_predicted_elliptic_last_two_months.csv'\n",
    "df_anomaly_data = load_data(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3841f7fe-e481-4d73-9fd3-83ca9b709789",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_labels = np.load('results/cluster_labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97001829-de23-4a0b-9f6d-a374532f810c",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_results = train_binary_classifier_for_clusters(loaded_labels, df_anomaly_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e3d1e9-7ad8-4718-9496-9b8765196705",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results/logit_regression_cluster_models_eval_10fold_results.json', \"w\") as outfile: \n",
    "        json.dump(logit_results, outfile, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c35082-f835-412f-bc48-547cc5ed6bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_results = train_binary_classifier_for_clusters(loaded_labels, df_anomaly_data, 'random_forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d78f52f-838f-4083-a1d0-c2332cd7fea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results/rf_cluster_models_eval_10fold_results.json', \"w\") as outfile: \n",
    "        json.dump(random_forest_results, outfile, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f29aa2-8b2f-40d2-9645-427eab034a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_results = train_binary_classifier_for_clusters(loaded_labels, df_anomaly_data, 'svm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba76148-e703-41d5-b205-ce6e71fb5df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results/svm_cluster_models_eval_10fold_results.json', \"w\") as outfile: \n",
    "        json.dump(svm_results, outfile, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61efb53a-83b0-4f56-bbad-8455113e018f",
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_bayes_results = train_binary_classifier_for_clusters(loaded_labels, df_anomaly_data, 'naive_bayes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42958f63-38c3-4df0-901e-124ce8670687",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results/nb_cluster_models_eval_10fold_results.json', \"w\") as outfile: \n",
    "        json.dump(naive_bayes_results, outfile, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28a15ca-804f-425d-8d84-62498a2d9c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_results, rf_classifiers = train_binary_classifier_for_clusters(loaded_labels, df_anomaly_data, 'random_forest', cv=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e9af9f-e167-4ffe-a3d4-8be11dc27abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dictionary containing trained models\n",
    "joblib.dump(rf_classifiers, 'models/rf_cluster_models.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbac6186-a11a-45ac-9dc0-d0c9fa5db3cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
