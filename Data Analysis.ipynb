{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f6651bca-0bde-4b1d-aebf-17852cc9b494",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, PowerTransformer\n",
    "import json \n",
    "base_dir = 'data\\\\LBNL_FDD_Dataset_SDAHU_all_3\\\\LBNL_FDD_Dataset_SDAHU\\\\'\n",
    "import pickle\n",
    "from sklearn.metrics import precision_recall_curve, auc,confusion_matrix\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "dd6f4358-5970-493e-982a-cfd9d52edcbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_name):\n",
    "    df = pd.read_csv(base_dir+file_name, index_col='Datetime')\n",
    "    df.index = pd.to_datetime(df.index, format='%Y-%m-%d %H:%M:%S')\n",
    "    return df\n",
    "\n",
    "def plot_line_graph(df1, df2, feature):\n",
    "    plt.plot(df1[feature].values, 'g')\n",
    "    plt.plot(df2[feature].values, 'r')\n",
    "    plt.show()\n",
    "\n",
    "import pandas as pd\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "def check_stationarity(data, column_name, significance_level=0.05):\n",
    "    \"\"\"\n",
    "    Check the stationarity of a time series using the Augmented Dickey-Fuller (ADF) test.\n",
    "\n",
    "    Parameters:\n",
    "    - data: pd.DataFrame\n",
    "        Input DataFrame with time series data.\n",
    "    - column_name: str\n",
    "        Name of the column containing the time series data.\n",
    "    - significance_level: float, optional (default=0.05)\n",
    "        Significance level for the ADF test.\n",
    "\n",
    "    Returns:\n",
    "    - bool\n",
    "        True if the time series is stationary, False otherwise.\n",
    "    \"\"\"\n",
    "\n",
    "    # Check if the specified column exists in the DataFrame\n",
    "    if column_name not in data.columns:\n",
    "        raise ValueError(f\"Column '{column_name}' not found in the DataFrame.\")\n",
    "\n",
    "    try:\n",
    "        # Perform the ADF test\n",
    "        result = adfuller(data[column_name])\n",
    "\n",
    "        # Extract ADF test statistic and p-value\n",
    "        adf_statistic = result[0]\n",
    "        p_value = result[1]\n",
    "    \n",
    "        # Compare p-value with significance level\n",
    "        is_stationary = p_value <= significance_level\n",
    "        \n",
    "        if stationary:\n",
    "            print(f\"The time series is stationary. ADF Statistic: {adf_statistic}, p-value: {p_value}\")\n",
    "        else:\n",
    "            print(f\"The time series is not stationary. ADF Statistic: {adf_statistic}, p-value: {p_value}\")\n",
    "            \n",
    "        #return is_stationary, adf_statistic, p_value\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "def drop_low_variance_features(data, threshold=0.01):\n",
    "    \n",
    "    # Calculate variance of each feature\n",
    "    variances = data.var()\n",
    "\n",
    "    #print(\"Variances of features:\")\n",
    "    #print(variances)\n",
    "\n",
    "    # Use VarianceThreshold to identify low variance features\n",
    "    selector = VarianceThreshold(threshold)\n",
    "    selector.fit(data)\n",
    "\n",
    "    # Get indices of features to keep\n",
    "    keep_indices = selector.get_support(indices=True)\n",
    "\n",
    "    # Subset the DataFrame with selected features\n",
    "    selected_data = data.iloc[:, keep_indices]\n",
    "\n",
    "    return selected_data\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def evaluate_classification_metrics(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Evaluate classification metrics such as accuracy, precision, recall, and F1 score.\n",
    "\n",
    "    Parameters:\n",
    "    - y_test: list or array-like\n",
    "        True labels.\n",
    "    - y_pred: list or array-like\n",
    "        Predicted labels.\n",
    "\n",
    "    Returns:\n",
    "    - dict\n",
    "        Dictionary containing evaluation metrics.\n",
    "    \"\"\"\n",
    "    # Initialize counts\n",
    "    TP = TN = FP = FN = 0\n",
    "\n",
    "    # Calculate confusion matrix elements\n",
    "    for true, predicted in zip(y_true, y_pred):\n",
    "        if true == 1 and predicted == 1:\n",
    "            TP += 1\n",
    "        elif true == 0 and predicted == 0:\n",
    "            TN += 1\n",
    "        elif true == 0 and predicted == 1:\n",
    "            FP += 1\n",
    "        elif true == 1 and predicted == 0:\n",
    "            FN += 1\n",
    "\n",
    "    print(\"TP:\", TP)\n",
    "    print(\"TN:\", TN)\n",
    "    print(\"FP:\", FP)\n",
    "    print(\"FN:\", FN)\n",
    "\n",
    "    # Compute classification metrics\n",
    "    accuracy = round(accuracy_score(y_true, y_pred), 2)\n",
    "    precision = round(precision_score(y_true, y_pred))\n",
    "    recall = round(recall_score(y_true, y_pred), 2)\n",
    "    f1 = round(f1_score(y_true, y_pred), 2)\n",
    "\n",
    "    # Create a dictionary to store the metrics\n",
    "    metrics_dict = {\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1\n",
    "    }\n",
    "\n",
    "    return metrics_dict\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "def visualize_optimal_clusters(data, max_clusters=10):\n",
    "    \"\"\"\n",
    "    Visualize the optimal number of clusters using the elbow method.\n",
    "\n",
    "    Parameters:\n",
    "    - data: array-like\n",
    "        The training data for clustering.\n",
    "    - max_clusters: int, optional (default=10)\n",
    "        Maximum number of clusters to consider.\n",
    "\n",
    "    Returns:\n",
    "    None (plots the elbow curve).\n",
    "    \"\"\"\n",
    "\n",
    "    distortions = []\n",
    "    \n",
    "    for i in range(1, max_clusters + 1):\n",
    "        kmeans = KMeans(n_clusters=i, random_state=42)\n",
    "        kmeans.fit(data)\n",
    "        distortions.append(kmeans.inertia_)\n",
    "\n",
    "    # Plotting the elbow curve\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(range(1, max_clusters + 1), distortions, marker='o')\n",
    "    plt.title('Elbow Method for Optimal Number of Clusters')\n",
    "    plt.xlabel('Number of Clusters')\n",
    "    plt.ylabel('Distortion (Inertia)')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def predict_and_assign_labels(kmeans_model, test_data):\n",
    "    \"\"\"\n",
    "    Predict cluster labels for test data and assign binary labels.\n",
    "\n",
    "    Parameters:\n",
    "    - kmeans_model: KMeans\n",
    "        Trained KMeans model.\n",
    "    - test_data: array-like\n",
    "        Test data for prediction.\n",
    "\n",
    "    Returns:\n",
    "    - binary_labels: array-like\n",
    "        Binary labels (0 or 1) assigned based on cluster membership.\n",
    "    \"\"\"\n",
    "\n",
    "    # Predict cluster labels for the test data\n",
    "    cluster_labels = kmeans_model.predict(test_data)\n",
    "    print(\"cluster labels\",cluster_labels) \n",
    "    # Assign binary labels (0 if in any cluster, 1 if not in any cluster)\n",
    "    binary_labels = np.where(cluster_labels >= 0, 0, 1)\n",
    "\n",
    "    return binary_labels\n",
    "\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def fine_tune_lof_model(non_faulty_data):\n",
    "    \"\"\"\n",
    "    Fine-tune Local Outlier Factor (LOF) model on non-faulty data.\n",
    "\n",
    "    Parameters:\n",
    "    - non_faulty_data: pd.DataFrame or 2D array\n",
    "        Non-faulty data for training the LOF model.\n",
    "\n",
    "    Returns:\n",
    "    - Trained LOF model.\n",
    "    \"\"\"\n",
    "\n",
    "    # Fine-tune LOF model using GridSearchCV\n",
    "    param_grid = {'n_neighbors': [5, 10, 15, 20], 'contamination': [0.01, 0.05, 0.1, 0.2]}\n",
    "    lof = LocalOutlierFactor(novelty=True)\n",
    "    grid_search = GridSearchCV(lof, param_grid, scoring='neg_mean_squared_error', cv=5, verbose=True)\n",
    "    grid_search.fit(non_faulty_data)\n",
    "\n",
    "    # Train the best LOF model with optimal hyperparameters\n",
    "    best_lof_model = LocalOutlierFactor(n_neighbors=grid_search.best_params_['n_neighbors'],\n",
    "                                        contamination=grid_search.best_params_['contamination'], novelty=True)\n",
    "    best_lof_model.fit(non_faulty_data)\n",
    "\n",
    "    return best_lof_model\n",
    "\n",
    "def evaluate_test_data(dict_fault, scaler, model, model_name, freq):\n",
    "    \n",
    "    results = {}\n",
    "    df_predict_faults_vals = pd.DataFrame()\n",
    "    df_hold_out_set_exp = pd.DataFrame()\n",
    "\n",
    "    for file in dict_fault.keys():\n",
    "        print(file)\n",
    "        df_test = dict_faulty_df[file][training_start_date_time : training_end_date_time].resample(freq).mean()\n",
    "        \n",
    "        df_hold_out_set_exp = pd.concat([df_hold_out_set_exp, dict_faulty_df[file][test_start_data:]])\n",
    "        \n",
    "        test_fft = np.fft.fft(df_test)\n",
    "        \n",
    "        y_true = [1]*len(df_test)\n",
    "        \n",
    "        labels = trained_lof_model.predict(scaler.transform(test_fft.real))\n",
    "        \n",
    "        binary_labels = np.where(labels == -1, 1, 0)\n",
    "\n",
    "        \n",
    "        metrics = evaluate_classification_metrics(y_true, binary_labels)\n",
    "        print(metrics)\n",
    "        results[file] = metrics\n",
    "        print()\n",
    "\n",
    "        fault_assignment = np.where(binary_labels == 1, True, False)\n",
    "        \n",
    "        fault_indices = np.where(fault_assignment)[0]\n",
    "        \n",
    "        df_faults_vals = df_test.iloc[fault_indices]\n",
    "        \n",
    "        df_predict_faults_vals = pd.concat([df_predict_faults_vals, df_faults_vals], ignore_index=True)\n",
    "        \n",
    "        \n",
    "    with open('results/'+model_name+'_results'+str(freq)+'.json', \"w\") as outfile: \n",
    "        json.dump(results, outfile, indent=4)\n",
    "        \n",
    "    df_predict_faults_vals.to_csv('results/'+model_name+'_predicted_faults_vals'+'_sampling_freq_'+str(freq)+'.csv', sep=',', index=False, encoding='utf-8')\n",
    "\n",
    "    df_hold_out_set_exp.to_csv('results/hold_out_test_set_explanations_sampling_freq_'+str(freq)+'.csv', sep=',', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "450b78e2-2ca5-47e6-aab9-2707f4608ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_data = load_data('AHU_annual.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4807aa7d-7be6-4c5a-802c-2cfd06e8ed61",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_faulty_df = {}\n",
    "for c, file in enumerate(os.listdir(base_dir)):\n",
    "    if c>0:\n",
    "        dict_faulty_df[file] = load_data(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1aa0cb7-bae7-48a9-8153-93b89b1d6f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_start_date_time = '2018-01-01 01:00:00'\n",
    "training_end_date_time = '2018-10-31 23:59:00'\n",
    "\n",
    "test_start_data = '2018-11-01 00:00:00'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "37b5b0b3-c402-460b-a5bb-990e6aaf8f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "resampling_freq = '1H'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "7168eeac-1e0b-41ef-8ead-7cf5e58dc23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = correct_data[training_start_date_time : training_end_date_time]\n",
    "df_valid = correct_data[test_start_data :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "0a8fe3e0-d09b-4f29-b177-65e186c2ba65",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_resampled = df_train.resample(resampling_freq).mean()\n",
    "df_valid_resampled = df_valid.resample(resampling_freq).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "fd975fb8-b9a7-4565-98f3-d4ed1e26760c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforming data from the time domain to the frequency domain using fast Fourier transform\n",
    "train_fft = np.fft.fft(df_train_resampled)\n",
    "valid_fft = np.fft.fft(df_train_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "1f147435-17bb-4f89-bb12-a6403d4302ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "train_scaled_fft = scaler.fit_transform(train_fft.real)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716603ce-5620-4261-833b-dded89e866c0",
   "metadata": {},
   "source": [
    "### Local Outlier Factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "4bf59d9a-a77e-4af1-ac3b-024290ac65a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    }
   ],
   "source": [
    "trained_lof_model = fine_tune_lof_model(train_scaled_fft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "e236d146-40c2-4677-abd8-7ec1e1c748e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 7262 occurrences\n",
      "1: 33 occurrences\n"
     ]
    }
   ],
   "source": [
    "valid_pred_labels = trained_lof_model.predict(scaler.transform(valid_fft.real))\n",
    "predicted_labels = np.where(valid_pred_labels == -1, 1, 0)\n",
    "valid_true_labels = [0]*len(valid_fft)\n",
    "\n",
    "value_counts = Counter(predicted_labels)\n",
    "\n",
    "#Print the counts\n",
    "for value, count in value_counts.items():\n",
    "    print(f\"{value}: {count} occurrences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "9893051c-d91f-4859-8d9e-1a3956106ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 0\n",
      "TN: 7262\n",
      "FP: 33\n",
      "FN: 0\n",
      "{'Accuracy': 1.0, 'Precision': 0, 'Recall': 0.0, 'F1 Score': 0.0}\n"
     ]
    }
   ],
   "source": [
    "metrics = evaluate_classification_metrics(valid_true_labels, predicted_labels)\n",
    "\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "2f654157-9661-4220-9251-de236c76570a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coi_bias_-2_annual.csv\n",
      "TP: 5989\n",
      "TN: 0\n",
      "FP: 0\n",
      "FN: 1306\n",
      "{'Accuracy': 0.82, 'Precision': 1, 'Recall': 0.82, 'F1 Score': 0.9}\n",
      "\n",
      "coi_bias_-4_annual.csv\n",
      "TP: 5391\n",
      "TN: 0\n",
      "FP: 0\n",
      "FN: 1904\n",
      "{'Accuracy': 0.74, 'Precision': 1, 'Recall': 0.74, 'F1 Score': 0.85}\n",
      "\n",
      "coi_bias_2_annual.csv\n",
      "TP: 6239\n",
      "TN: 0\n",
      "FP: 0\n",
      "FN: 1056\n",
      "{'Accuracy': 0.86, 'Precision': 1, 'Recall': 0.86, 'F1 Score': 0.92}\n",
      "\n",
      "coi_bias_4_annual.csv\n",
      "TP: 6011\n",
      "TN: 0\n",
      "FP: 0\n",
      "FN: 1284\n",
      "{'Accuracy': 0.82, 'Precision': 1, 'Recall': 0.82, 'F1 Score': 0.9}\n",
      "\n",
      "coi_leakage_010_annual.csv\n",
      "TP: 6203\n",
      "TN: 0\n",
      "FP: 0\n",
      "FN: 1092\n",
      "{'Accuracy': 0.85, 'Precision': 1, 'Recall': 0.85, 'F1 Score': 0.92}\n",
      "\n",
      "coi_leakage_025_annual.csv\n",
      "TP: 6203\n",
      "TN: 0\n",
      "FP: 0\n",
      "FN: 1092\n",
      "{'Accuracy': 0.85, 'Precision': 1, 'Recall': 0.85, 'F1 Score': 0.92}\n",
      "\n",
      "coi_leakage_040_annual.csv\n",
      "TP: 6203\n",
      "TN: 0\n",
      "FP: 0\n",
      "FN: 1092\n",
      "{'Accuracy': 0.85, 'Precision': 1, 'Recall': 0.85, 'F1 Score': 0.92}\n",
      "\n",
      "coi_leakage_050_annual.csv\n",
      "TP: 6203\n",
      "TN: 0\n",
      "FP: 0\n",
      "FN: 1092\n",
      "{'Accuracy': 0.85, 'Precision': 1, 'Recall': 0.85, 'F1 Score': 0.92}\n",
      "\n",
      "coi_stuck_010_annual.csv\n",
      "TP: 3052\n",
      "TN: 0\n",
      "FP: 0\n",
      "FN: 4243\n",
      "{'Accuracy': 0.42, 'Precision': 1, 'Recall': 0.42, 'F1 Score': 0.59}\n",
      "\n",
      "coi_stuck_025_annual.csv\n",
      "TP: 3888\n",
      "TN: 0\n",
      "FP: 0\n",
      "FN: 3407\n",
      "{'Accuracy': 0.53, 'Precision': 1, 'Recall': 0.53, 'F1 Score': 0.7}\n",
      "\n",
      "coi_stuck_050_annual.csv\n",
      "TP: 5879\n",
      "TN: 0\n",
      "FP: 0\n",
      "FN: 1416\n",
      "{'Accuracy': 0.81, 'Precision': 1, 'Recall': 0.81, 'F1 Score': 0.89}\n",
      "\n",
      "coi_stuck_075_annual.csv\n",
      "TP: 5903\n",
      "TN: 0\n",
      "FP: 0\n",
      "FN: 1392\n",
      "{'Accuracy': 0.81, 'Precision': 1, 'Recall': 0.81, 'F1 Score': 0.89}\n",
      "\n",
      "damper_stuck_010_annual.csv\n",
      "TP: 6464\n",
      "TN: 0\n",
      "FP: 0\n",
      "FN: 831\n",
      "{'Accuracy': 0.89, 'Precision': 1, 'Recall': 0.89, 'F1 Score': 0.94}\n",
      "\n",
      "damper_stuck_025_annual.csv\n",
      "TP: 6370\n",
      "TN: 0\n",
      "FP: 0\n",
      "FN: 925\n",
      "{'Accuracy': 0.87, 'Precision': 1, 'Recall': 0.87, 'F1 Score': 0.93}\n",
      "\n",
      "damper_stuck_075_annual.csv\n",
      "TP: 4713\n",
      "TN: 0\n",
      "FP: 0\n",
      "FN: 2582\n",
      "{'Accuracy': 0.65, 'Precision': 1, 'Recall': 0.65, 'F1 Score': 0.78}\n",
      "\n",
      "damper_stuck_100_annual_short.csv\n",
      "TP: 4245\n",
      "TN: 0\n",
      "FP: 0\n",
      "FN: 890\n",
      "{'Accuracy': 0.83, 'Precision': 1, 'Recall': 0.83, 'F1 Score': 0.91}\n",
      "\n",
      "oa_bias_-2_annual.csv\n",
      "TP: 6256\n",
      "TN: 0\n",
      "FP: 0\n",
      "FN: 1039\n",
      "{'Accuracy': 0.86, 'Precision': 1, 'Recall': 0.86, 'F1 Score': 0.92}\n",
      "\n",
      "oa_bias_-4_annual.csv\n",
      "TP: 6256\n",
      "TN: 0\n",
      "FP: 0\n",
      "FN: 1039\n",
      "{'Accuracy': 0.86, 'Precision': 1, 'Recall': 0.86, 'F1 Score': 0.92}\n",
      "\n",
      "oa_bias_2_annual.csv\n",
      "TP: 6256\n",
      "TN: 0\n",
      "FP: 0\n",
      "FN: 1039\n",
      "{'Accuracy': 0.86, 'Precision': 1, 'Recall': 0.86, 'F1 Score': 0.92}\n",
      "\n",
      "oa_bias_4_annual.csv\n",
      "TP: 6256\n",
      "TN: 0\n",
      "FP: 0\n",
      "FN: 1039\n",
      "{'Accuracy': 0.86, 'Precision': 1, 'Recall': 0.86, 'F1 Score': 0.92}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_test_data(dict_faulty_df, scaler, trained_lof_model, 'LOF', resampling_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "542cc06e-3c47-484b-b27e-d2687852dcf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/minmax_model_1H.pkl']"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the model to a file\n",
    "joblib.dump(trained_lof_model, 'models/lof_model_'+str(resampling_freq)+'.pkl')\n",
    "joblib.dump(scaler, 'models/minmax_model_'+str(resampling_freq)+'.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87af85f8-d3ba-44b2-83f0-fe770c93c02c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
