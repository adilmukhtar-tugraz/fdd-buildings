{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "135e0f41-41a7-4464-b18e-9954552fdce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "236bad8e-aea8-483b-8e61-90b6e95dfe99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_name):\n",
    "    df = pd.read_csv('dataset/LBNL_FDD_Dataset_SDAHU_all_3/LBNL_FDD_Dataset_SDAHU/'+file_name)\n",
    "    return df\n",
    "\n",
    "def save_df(df, file_name):\n",
    "    df.to_csv('dataset/LBNL_FDD_Dataset_SDAHU_all_3/LBNL_FDD_Dataset_SDAHU/'+file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae4329f9-49ed-487c-b8ab-0930e3d4346a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_correct = load_data('correct_data.csv')\n",
    "df_correct.drop(['Unnamed: 0'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "053efab3-0f1c-490e-82a9-cb72f615dc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(df_correct.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "1258a38a-74b7-4c7b-8a1e-a709683eee53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MA_TEMP', 'RA_TEMP', 'RF_WAT']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "0047b23a-0287-43f7-a107-0b09567a913c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "def remove_low_variance_features(df, threshold=0.1):\n",
    "    \"\"\"\n",
    "    Prints the variance of each feature and removes features with variance below the threshold.\n",
    "\n",
    "    Parameters:\n",
    "    - df: pandas DataFrame\n",
    "        The input DataFrame with features.\n",
    "    - threshold: float, optional (default=0.1)\n",
    "        The threshold below which features will be removed.\n",
    "\n",
    "    Returns:\n",
    "    - df_filtered: pandas DataFrame\n",
    "        The DataFrame with low variance features removed.\n",
    "    \"\"\"\n",
    "    # Calculate variance for each feature\n",
    "    feature_variances = df.var()\n",
    "\n",
    "    # Print the variance of each feature\n",
    "    print(\"Feature Variances:\")\n",
    "    print(feature_variances)\n",
    "\n",
    "    # Create a VarianceThreshold instance\n",
    "    variance_threshold = VarianceThreshold(threshold=threshold)\n",
    "\n",
    "    # Fit and transform the data to remove low variance features\n",
    "    df_filtered = pd.DataFrame(variance_threshold.fit_transform(df), columns=df.columns[feature_variances >= threshold])\n",
    "\n",
    "    # Print the selected features\n",
    "    selected_features = df.columns[feature_variances >= threshold]\n",
    "    print(f\"\\nSelected Features (with variance >= {threshold}):\")\n",
    "    print(selected_features)\n",
    "\n",
    "    return df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "63fd7edb-d8d6-4c43-941e-2f0592fbb1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_of_absolute_difference(lst):\n",
    "    sum_abs_diff = 0\n",
    "    n = len(lst)\n",
    "    for i in range(n-1):\n",
    "        sum_abs_diff += abs(lst[i+1] - lst[i])\n",
    "    return sum_abs_diff\n",
    "def safe_min(arr):\n",
    "    \"\"\"\n",
    "    Safely computes the minimum of an array, handling zero-size arrays and NaN values.\n",
    "    \n",
    "    Parameters:\n",
    "    - arr: numpy array\n",
    "        The input array.\n",
    "    \n",
    "    Returns:\n",
    "    - minimum: float or numpy.nan\n",
    "        The minimum value, or numpy.nan if the array is empty or contains NaN values.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        minimum = np.min(arr)\n",
    "        return minimum\n",
    "    except ValueError as e:\n",
    "        pass\n",
    "    \n",
    "def safe_max(arr):\n",
    "    \"\"\"\n",
    "    Safely computes the minimum of an array, handling zero-size arrays and NaN values.\n",
    "    \n",
    "    Parameters:\n",
    "    - arr: numpy array\n",
    "        The input array.\n",
    "    \n",
    "    Returns:\n",
    "    - minimum: float or numpy.nan\n",
    "        The minimum value, or numpy.nan if the array is empty or contains NaN values.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        maximum = np.max(arr)\n",
    "        return maximum\n",
    "    except ValueError as e:\n",
    "        pass\n",
    "    \n",
    "def interval_feature_transformation(df, window_size, fault_time=None):\n",
    "    dict_ift = {}\n",
    "    list_interval_features = ['mean', 'std', 'd', 'min', 'peak']\n",
    "    for feat in df.keys():\n",
    "        dict_ift[feat] = {}\n",
    "        for interval_feature in list_interval_features:\n",
    "            dict_ift[feat][feat+'-'+interval_feature] = []\n",
    "    window_counter = 1\n",
    "    list_ma_temp = []\n",
    "    list_ra_temp = []\n",
    "    list_rf_wat = []\n",
    "    list_labels = []\n",
    "    for row in df.iterrows():\n",
    "\n",
    "        list_ma_temp.append(row[1][0]) # append MA_TEMP\n",
    "        list_ra_temp.append(row[1][1]) # append RA_TEMP\n",
    "        list_rf_wat.append(row[1][2]) # append RF_WAT\n",
    "\n",
    "\n",
    "        if row[0]==window_size*window_counter or row[0]==len(df)-1:\n",
    "            window_counter+=1\n",
    "\n",
    "            for feature in dict_ift.keys():\n",
    "                \n",
    "                if feature == 'MA_TEMP':\n",
    "\n",
    "                    mean_ma_temp = np.mean(list_ma_temp)\n",
    "                    std_ma_temp = np.std(list_ma_temp)\n",
    "\n",
    "                    dict_ift[feature][feature+'-'+'mean'].append(mean_ma_temp)\n",
    "\n",
    "                    dict_ift[feature][feature+'-'+'std'].append(std_ma_temp)\n",
    "\n",
    "                    dict_ift[feature][feature+'-'+'d'].append(sum_of_absolute_difference(list_ma_temp))\n",
    " \n",
    "                    dict_ift[feature][feature+'-'+'min'].append(safe_min(list_ma_temp))\n",
    "\n",
    "                    dict_ift[feature][feature+'-'+'peak'].append(safe_max(list_ma_temp))\n",
    "\n",
    "                    #dict_ift[feature]['skew'].append(skewness(list_current, mean_curr, std_curr))\n",
    "\n",
    "                    #dict_ift[feature]['kurt'].append(kurtosis(list_current, mean_curr, std_curr))\n",
    "                    #dict_ift[feature]['kurt'].append(kurtosis(list_current))\n",
    "\n",
    "                elif feature == 'RA_TEMP':\n",
    "\n",
    "                    mean_ra_temp = np.mean(list_ra_temp)\n",
    "                    std_ra_temp = np.std(list_ra_temp)\n",
    "\n",
    "                    dict_ift[feature][feature+'-'+'mean'].append(mean_ra_temp)\n",
    "\n",
    "                    dict_ift[feature][feature+'-'+'std'].append(std_ra_temp)\n",
    "\n",
    "                    dict_ift[feature][feature+'-'+'d'].append(sum_of_absolute_difference(list_ra_temp))\n",
    "                    \n",
    "                    dict_ift[feature][feature+'-'+'min'].append(safe_min(list_ra_temp))\n",
    "                    \n",
    "                    dict_ift[feature][feature+'-'+'peak'].append(safe_max(list_ra_temp))\n",
    "                    \n",
    "                    #dict_ift[feature]['skew'].append(skewness(list_voltage, mean_volt, std_volt))\n",
    "\n",
    "                    #dict_ift[feature]['kurt'].append(kurtosis(list_voltage, mean_volt, std_volt))\n",
    "                    #dict_ift[feature]['kurt'].append(kurtosis(list_voltage))\n",
    "\n",
    "                elif feature == 'RF_WAT':\n",
    "     \n",
    "                    mean_rf_wat = np.mean(list_rf_wat)\n",
    "                    std_rf_wat = np.std(list_rf_wat)\n",
    "\n",
    "                    dict_ift[feature][feature+'-'+'mean'].append(mean_rf_wat)\n",
    "\n",
    "                    dict_ift[feature][feature+'-'+'std'].append(std_rf_wat)\n",
    "\n",
    "                    dict_ift[feature][feature+'-'+'d'].append(sum_of_absolute_difference(list_rf_wat))\n",
    "                    \n",
    "                    dict_ift[feature][feature+'-'+'min'].append(safe_min(list_rf_wat))\n",
    "\n",
    "                    dict_ift[feature][feature+'-'+'peak'].append(safe_max(list_rf_wat))\n",
    "                    \n",
    "                    #dict_ift[feature]['skew'].append(skewness(list_rotations, mean_rot, std_rot))\n",
    "\n",
    "                    #dict_ift[feature]['kurt'].append(kurtosis(list_rotations, mean_rot, std_rot))\n",
    "                    #dict_ift[feature]['kurt'].append(kurtosis(list_rotations))\n",
    "\n",
    "            list_ma_temp = []\n",
    "            list_ra_temp = []\n",
    "            list_rf_wat = []\n",
    "    df_transformed_ma_temp = pd.DataFrame(dict_ift['MA_TEMP'])\n",
    "    df_transformed_ra_temp = pd.DataFrame(dict_ift['RA_TEMP'])\n",
    "    df_transformed_rf_wat = pd.DataFrame(dict_ift['RF_WAT'])\n",
    "    \n",
    "    result = pd.concat([df_transformed_ma_temp, df_transformed_ra_temp, df_transformed_rf_wat], axis=1)\n",
    "\n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "409348e8-79c0-473d-ac43-c5351abbe9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_correct_transformed_10mins = interval_feature_transformation(df_correct, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b60d20d1-dfc0-419a-93b8-d7e4d861ad86",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_correct_transformed_10mins.to_csv('dataset/ift_transormed_correct_10mins.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "0e4efa56-79b5-4aa0-939a-3c1419cc95a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_correct_transformed_20mins = interval_feature_transformation(df_correct, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "014a751a-6882-4b1c-b5ea-ba8d2a9edf1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_correct_transformed_20mins.to_csv('dataset/ift_transormed_correct_20mins.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "35b51ca7-1f47-41f0-9d34-0693de51412a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_damper_stuck_010 = load_data('damper_stuck_010_annual.csv')\n",
    "df_damper_stuck_025 = load_data('damper_stuck_025_annual.csv')\n",
    "df_damper_stuck_075 = load_data('damper_stuck_075_annual.csv')\n",
    "df_damper_stuck_100 = load_data('damper_stuck_100_annual_short.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "a039bc36-8945-44f2-9615-b9a8e0b1a8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_damper_stuck_010_10mins = interval_feature_transformation(df_damper_stuck_010[features], 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "a1dc9def-d009-442f-8acb-13f32d2eb53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_damper_stuck_010_20mins = interval_feature_transformation(df_damper_stuck_010[features], 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "239b25b2-29d5-4cba-be7c-08c6ca947423",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_df(df_damper_stuck_010_10mins, 'ift_transormed_damper_stuck_010_10mins.csv')\n",
    "save_df(df_damper_stuck_010_20mins, 'ift_transormed_damper_stuck_010_20mins.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "edc807ad-9b23-46b7-b9e9-d319a1f44c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_damper_stuck_025_10mins = interval_feature_transformation(df_damper_stuck_025[features], 10)\n",
    "df_damper_stuck_025_20mins = interval_feature_transformation(df_damper_stuck_025[features], 20)\n",
    "save_df(df_damper_stuck_025_10mins, 'ift_transormed_damper_stuck_025_10mins.csv')\n",
    "save_df(df_damper_stuck_025_20mins, 'ift_transormed_damper_stuck_025_20mins.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "5d7ae36a-da45-4aa6-b094-937fc41f9567",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_damper_stuck_075_10mins = interval_feature_transformation(df_damper_stuck_075[features], 10)\n",
    "df_damper_stuck_075_20mins = interval_feature_transformation(df_damper_stuck_075[features], 20)\n",
    "save_df(df_damper_stuck_075_10mins, 'ift_transormed_damper_stuck_075_10mins.csv')\n",
    "save_df(df_damper_stuck_075_20mins, 'ift_transormed_damper_stuck_075_20mins.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "e8fd48e4-c585-430a-b0d6-c1726f42142d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_damper_stuck_100_10mins = interval_feature_transformation(df_damper_stuck_100[features], 10)\n",
    "df_damper_stuck_100_20mins = interval_feature_transformation(df_damper_stuck_100[features], 20)\n",
    "save_df(df_damper_stuck_100_10mins, 'ift_transormed_damper_stuck_100_10mins.csv')\n",
    "save_df(df_damper_stuck_100_20mins, 'ift_transormed_damper_stuck_100_20mins.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9cbb9c-4175-4d4c-869b-7d8c636e1afc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
